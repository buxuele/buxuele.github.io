{"meta":{"title":"Legend","subtitle":"jsut rolling","description":"test something","author":"buxuele","url":"http://buxuele.github.io"},"pages":[{"title":"about_me","date":"2018-04-21T03:44:01.000Z","updated":"2018-04-21T10:33:24.992Z","comments":true,"path":"about-me/index.html","permalink":"http://buxuele.github.io/about-me/index.html","excerpt":"","text":"If there’s anything you want to tell me ,please send:baogebuxuele@163.com"},{"title":"tags","date":"2018-04-21T07:11:40.000Z","updated":"2018-04-21T07:11:40.236Z","comments":true,"path":"tags/index.html","permalink":"http://buxuele.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"430_west_world_season_2","slug":"430-west-world-season-2","date":"2018-04-30T14:54:12.000Z","updated":"2018-04-30T14:57:31.494Z","comments":true,"path":"2018/04/30/430-west-world-season-2/","link":"","permalink":"http://buxuele.github.io/2018/04/30/430-west-world-season-2/","excerpt":"","text":"west world s2e2","categories":[],"tags":[]},{"title":"430zhiboba","slug":"430zhiboba","date":"2018-04-29T16:07:23.000Z","updated":"2018-04-29T16:10:02.438Z","comments":true,"path":"2018/04/30/430zhiboba/","link":"","permalink":"http://buxuele.github.io/2018/04/30/430zhiboba/","excerpt":"","text":"尝试下载直播吧的图片 ，还需要改进 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101# -*- coding: utf-8 -*-# author: fanchuangwater Administrator# time: 2018/4/29 21:15# about: 尝试下载直播吧的图片# 这个 版本还需要再改进。。。import reimport timeimport osimport requestsfrom bs4 import BeautifulSoupfrom multiprocessing.dummy import Poolfrom fake_useragent import UserAgentu = UserAgent()# url = &apos;https://tu.zhibo8.cc/home/album/40517/&apos;headers = &#123; &apos;User-Agent&apos;: u.random&#125;start_url = &apos;https://tu.zhibo8.cc/zuqiu/all/3&apos;# 访问一个网页 ，返回 responsedef ask_page(url): s = requests.Session() page = s.get(url, headers=headers) # print(page.status_code) # print(page.encoding) return page# 找到网页中想要的链接，并返回def get_link(url): page = ask_page(url) soup = BeautifulSoup(page.text, &apos;lxml&apos;) lis = soup.find_all(src=re.compile(&apos;imgcdn.zhibo8.cc&apos;)) print(len(lis)) # 17 for l in lis[1: -6]: # print(l) # print(l.get(&apos;src&apos;)) u = &apos;https:&apos; + l.get(&apos;src&apos;)[: -10] + l.get(&apos;src&apos;)[-4:] # print(u) yield u# 下载图片def download(url): print(&quot;正在下载：&quot; + url) pic = ask_page(url).content # 获取图片的内容 fn = url.split(&apos;/&apos;)[-1] with open(fn, &apos;wb&apos;) as f: f.write(pic)#def feed(start_url): full_pages = [] bo = ask_page(start_url) soup = BeautifulSoup(bo.text, &apos;lxml&apos;) ss = soup.find_all(href=re.compile(r&apos;/home/album/&apos;)) sss = ss[: -11] for s in range(len(sss)): if s % 2 == 0: # print(s.get(&apos;href&apos;)) print(sss[s].get(&apos;href&apos;)) full_page = &apos;https://tu.zhibo8.cc&apos; + sss[s].get(&apos;href&apos;) full_pages.append(full_page) return full_pages# 多线程下载if __name__ == &apos;__main__&apos;: # os.makedirs(&apos;z2&apos;, exist_ok=True) os.chdir(&apos;z2&apos;) start = time.time() for url in feed(start_url): lse = get_link(url) pool = Pool(20) pool.map(download, lse) pool.close() pool.join() end = time.time() print(&quot;下载完成！下载一共消耗的时间是：&quot; + str(end - start)) # ask_page(url) # get_link(url) # feed(start_url)","categories":[],"tags":[]},{"title":"卫国勇士","slug":"卫国勇士","date":"2018-04-28T16:55:45.000Z","updated":"2018-04-28T16:59:17.553Z","comments":true,"path":"2018/04/29/卫国勇士/","link":"","permalink":"http://buxuele.github.io/2018/04/29/卫国勇士/","excerpt":"","text":"女主角。","categories":[],"tags":[]},{"title":"423rain","slug":"423rain","date":"2018-04-23T13:10:41.000Z","updated":"2018-04-23T13:14:43.083Z","comments":true,"path":"2018/04/23/423rain/","link":"","permalink":"http://buxuele.github.io/2018/04/23/423rain/","excerpt":"","text":"下雨了。对于发芽的种子是个好事。","categories":[],"tags":[]},{"title":"plant01","slug":"422plant01","date":"2018-04-22T15:05:35.000Z","updated":"2018-04-23T13:14:45.075Z","comments":true,"path":"2018/04/22/422plant01/","link":"","permalink":"http://buxuele.github.io/2018/04/22/422plant01/","excerpt":"","text":"阳台的花盆，放了一些种子。发芽了。","categories":[],"tags":[]},{"title":"rename_files_with_python","slug":"rename-files-with-python","date":"2018-04-21T14:12:36.000Z","updated":"2018-04-21T14:14:48.018Z","comments":true,"path":"2018/04/21/rename-files-with-python/","link":"","permalink":"http://buxuele.github.io/2018/04/21/rename-files-with-python/","excerpt":"","text":"借鉴了别人的写法，稍微改下：123456789101112131415161718192021222324252627282930313233 # -*- coding: utf-8 -*-# author: fanchuangwater Administrator# time: 2018/4/21 20:28# description: 批量重命名文件import ospath_name = input(&quot;Your file path: &quot;)def rename_files(path_name): i = 0 all_file = os.listdir(path_name) for a in all_file: print(a) old_file = os.path.join(path_name, a) print(old_file) b = str(i) + a[-4:] print(b) new_file = os.path.join(path_name, b) print(new_file) os.rename(old_file, new_file) print(&apos;***************&apos;) i = i + 1rename_files(path_name)","categories":[],"tags":[]},{"title":"pic_test","slug":"pic-test","date":"2018-04-21T11:14:42.000Z","updated":"2018-04-22T15:15:29.788Z","comments":true,"path":"2018/04/21/pic-test/","link":"","permalink":"http://buxuele.github.io/2018/04/21/pic-test/","excerpt":"","text":"test some thing about markdown 插入网络图片测试01 本地图片测试02","categories":[],"tags":[]}]}